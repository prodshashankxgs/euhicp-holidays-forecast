{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# EU HICP Package Holidays Price Forecast - Phase 2: Exploratory Data Analysis\n",
        "\n",
        "## Overview\n",
        "This notebook implements **Phase 2** of the EU HICP Package Holidays Price Forecast project, focusing on comprehensive exploratory data analysis using interactive plotly visualizations to understand seasonal patterns, cross-country dynamics, and key economic relationships.\n",
        "\n",
        "### Objectives\n",
        "1. **Interactive Time Series Analysis**: Visualize HICP trends with seasonal highlighting\n",
        "2. **Seasonal Pattern Discovery**: Create heatmaps and decomposition analysis\n",
        "3. **Cross-Country Comparison**: Analyze EU vs Germany package holiday dynamics\n",
        "4. **Economic Indicator Relationships**: Explore correlations with oil prices, exchange rates, etc.\n",
        "5. **Holiday Period Impact**: Statistical analysis of summer tourism effects\n",
        "6. **Outlier Detection**: Identify and analyze unusual price movements\n",
        "\n",
        "### Key Insights We'll Discover\n",
        "- **Summer Seasonality**: How strong are June-August price increases?\n",
        "- **Cross-Country Divergence**: Do Germany and EU-wide patterns align?\n",
        "- **Economic Drivers**: Which indicators best predict holiday price changes?\n",
        "- **Historical Patterns**: What can past data tell us about July 2025?\n",
        "\n",
        "### Visualization Technologies\n",
        "- **Interactive Charts**: Plotly for dynamic exploration\n",
        "- **Statistical Analysis**: Polars for efficient computation\n",
        "- **Dashboard Creation**: Multi-panel comprehensive views\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import os\n",
        "from scipy import stats\n",
        "import json\n",
        "\n",
        "# Add project root to path for imports\n",
        "sys.path.append('.')\n",
        "\n",
        "# Import project modules\n",
        "from visualization_utils import HICPVisualizer, create_statistical_summary, COLORS\n",
        "from data_collector import DataCollector\n",
        "\n",
        "# Configure settings\n",
        "pl.Config.set_tbl_rows(15)\n",
        "pl.Config.set_tbl_cols(12)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✓ All libraries imported successfully\")\n",
        "print(f\"Polars version: {pl.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "\n",
        "# Initialize visualizer\n",
        "viz = HICPVisualizer(theme='plotly_white')\n",
        "print(\"✓ HICP Visualizer initialized\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Step 1: Load and Validate Phase 1 Data\n",
        "\n",
        "First, we'll load the cleaned data from Phase 1 and validate its structure and quality for our exploratory analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load cleaned data from Phase 1\n",
        "def load_phase1_data():\n",
        "    \"\"\"Load and validate cleaned data from Phase 1.\"\"\"\n",
        "    \n",
        "    try:\n",
        "        # Try to load parquet files first (faster)\n",
        "        long_data = pl.read_parquet('data/clean_long_format.parquet')\n",
        "        wide_data = pl.read_parquet('data/clean_wide_format.parquet')\n",
        "        \n",
        "        print(\"✓ Successfully loaded parquet data files\")\n",
        "        \n",
        "    except FileNotFoundError:\n",
        "        try:\n",
        "            # Fallback to CSV files\n",
        "            long_data = pl.read_csv('data/clean_long_format.csv')\n",
        "            wide_data = pl.read_csv('data/clean_wide_format.csv')\n",
        "            \n",
        "            # Ensure proper data types for CSV\n",
        "            long_data = long_data.with_columns([\n",
        "                pl.col('date').str.strptime(pl.Date, format='%Y-%m-%d'),\n",
        "                pl.col('value').cast(pl.Float64),\n",
        "                pl.col('value_filled').cast(pl.Float64),\n",
        "                pl.col('mom_pct_change').cast(pl.Float64),\n",
        "                pl.col('yoy_pct_change').cast(pl.Float64)\n",
        "            ])\n",
        "            \n",
        "            wide_data = wide_data.with_columns([\n",
        "                pl.col('date').str.strptime(pl.Date, format='%Y-%m-%d')\n",
        "            ])\n",
        "            \n",
        "            print(\"✓ Successfully loaded CSV data files\")\n",
        "            \n",
        "        except FileNotFoundError:\n",
        "            print(\"❌ No cleaned data files found!\")\n",
        "            print(\"Please run Phase 1 (01_data_collection_and_cleaning.ipynb) first\")\n",
        "            return None, None, {}\n",
        "    \n",
        "    # Load metadata if available\n",
        "    try:\n",
        "        with open('data/data_metadata.json', 'r') as f:\n",
        "            metadata = json.load(f)\n",
        "        print(\"✓ Loaded metadata file\")\n",
        "    except FileNotFoundError:\n",
        "        metadata = {}\n",
        "        print(\"⚠️ No metadata file found\")\n",
        "    \n",
        "    return long_data, wide_data, metadata\n",
        "\n",
        "# Load the data\n",
        "long_data, wide_data, metadata = load_phase1_data()\n",
        "\n",
        "# Validate data structure\n",
        "if long_data is not None and wide_data is not None:\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"DATA VALIDATION SUMMARY\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    print(f\"Long format data: {long_data.height:,} rows × {long_data.width} columns\")\n",
        "    print(f\"Wide format data: {wide_data.height:,} rows × {wide_data.width} columns\")\n",
        "    \n",
        "    if not long_data.is_empty():\n",
        "        print(f\"Date range: {long_data['date'].min()} to {long_data['date'].max()}\")\n",
        "        print(f\"Available series: {long_data['series_name'].n_unique()}\")\n",
        "        \n",
        "        # Show available series\n",
        "        series_list = long_data['series_name'].unique().to_list()\n",
        "        print(f\"Series names:\")\n",
        "        for series in series_list:\n",
        "            count = long_data.filter(pl.col('series_name') == series).height\n",
        "            print(f\"  • {series}: {count:,} observations\")\n",
        "    \n",
        "    # Check for key HICP series\n",
        "    key_series = ['eu_package_holidays', 'germany_package_holidays']\n",
        "    missing_series = []\n",
        "    \n",
        "    for series in key_series:\n",
        "        if series not in long_data['series_name'].unique().to_list():\n",
        "            missing_series.append(series)\n",
        "    \n",
        "    if missing_series:\n",
        "        print(f\"\\n⚠️ Missing key series: {missing_series}\")\n",
        "        print(\"Note: Analysis will be limited without core HICP data\")\n",
        "    else:\n",
        "        print(f\"\\n✓ All key HICP series are available\")\n",
        "        \n",
        "else:\n",
        "    print(\"❌ Cannot proceed without data. Please run Phase 1 first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Step 2: Interactive Time Series Visualization\n",
        "\n",
        "Let's create comprehensive interactive time series plots to understand the overall trends and patterns in our HICP data. These visualizations will highlight seasonal periods and allow for detailed exploration of the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create interactive time series visualizations\n",
        "if long_data is not None and not long_data.is_empty():\n",
        "    \n",
        "    print(\"Creating interactive time series visualizations...\")\n",
        "    \n",
        "    # 1. Main HICP Index Levels\n",
        "    print(\"\\n1. HICP Index Levels Over Time\")\n",
        "    fig_levels = viz.create_time_series_plot(\n",
        "        df=long_data,\n",
        "        value_col='value_filled',\n",
        "        title=\"EU HICP Package Holidays Index Levels\",\n",
        "        yaxis_title=\"Index Value\",\n",
        "        show_trend=True,\n",
        "        highlight_seasons=True\n",
        "    )\n",
        "    fig_levels.show()\n",
        "    \n",
        "    # 2. Month-over-Month Percentage Changes\n",
        "    print(\"\\n2. Month-over-Month Percentage Changes\")\n",
        "    fig_mom = viz.create_time_series_plot(\n",
        "        df=long_data,\n",
        "        value_col='mom_pct_change',\n",
        "        title=\"HICP Package Holidays - Month-over-Month Changes (%)\",\n",
        "        yaxis_title=\"MoM Change (%)\",\n",
        "        show_trend=True,\n",
        "        highlight_seasons=True\n",
        "    )\n",
        "    \n",
        "    # Add zero line for reference\n",
        "    fig_mom.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\", opacity=0.5)\n",
        "    fig_mom.show()\n",
        "    \n",
        "    # 3. Year-over-Year Percentage Changes\n",
        "    print(\"\\n3. Year-over-Year Percentage Changes\")\n",
        "    fig_yoy = viz.create_time_series_plot(\n",
        "        df=long_data,\n",
        "        value_col='yoy_pct_change',\n",
        "        title=\"HICP Package Holidays - Year-over-Year Changes (%)\",\n",
        "        yaxis_title=\"YoY Change (%)\",\n",
        "        show_trend=True,\n",
        "        highlight_seasons=True\n",
        "    )\n",
        "    \n",
        "    # Add zero line for reference\n",
        "    fig_yoy.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\", opacity=0.5)\n",
        "    fig_yoy.show()\n",
        "    \n",
        "    # 4. Focus on Key HICP Series Comparison\n",
        "    hicp_series = ['eu_package_holidays', 'germany_package_holidays']\n",
        "    available_hicp = [s for s in hicp_series if s in long_data['series_name'].unique().to_list()]\n",
        "    \n",
        "    if available_hicp:\n",
        "        print(f\"\\n4. EU vs Germany HICP Comparison\")\n",
        "        hicp_data = long_data.filter(pl.col('series_name').is_in(available_hicp))\n",
        "        \n",
        "        fig_comparison = viz.create_time_series_plot(\n",
        "            df=hicp_data,\n",
        "            value_col='mom_pct_change',\n",
        "            title=\"EU vs Germany Package Holidays HICP - MoM Changes Comparison\",\n",
        "            yaxis_title=\"MoM Change (%)\",\n",
        "            show_trend=True,\n",
        "            highlight_seasons=True\n",
        "        )\n",
        "        \n",
        "        # Add zero line and enhance styling\n",
        "        fig_comparison.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\", opacity=0.5)\n",
        "        fig_comparison.update_layout(\n",
        "            annotations=[\n",
        "                dict(\n",
        "                    text=\"Summer Tourism Season Highlighted\",\n",
        "                    xref=\"paper\", yref=\"paper\",\n",
        "                    x=0.02, y=0.98,\n",
        "                    showarrow=False,\n",
        "                    font=dict(size=10, color=\"orange\"),\n",
        "                    bgcolor=\"rgba(255,255,255,0.8)\"\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "        fig_comparison.show()\n",
        "        \n",
        "    else:\n",
        "        print(\"⚠️ No HICP series available for comparison\")\n",
        "    \n",
        "else:\n",
        "    print(\"❌ No data available for time series visualization\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Step 3: Seasonal Pattern Analysis\n",
        "\n",
        "Now let's dive deep into seasonal patterns using heatmaps and decomposition analysis. This will help us understand the recurring patterns that are crucial for forecasting July 2025.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Seasonal pattern analysis\n",
        "if long_data is not None and not long_data.is_empty():\n",
        "    \n",
        "    print(\"Analyzing seasonal patterns...\")\n",
        "    \n",
        "    # Get available HICP series for analysis\n",
        "    hicp_series = ['eu_package_holidays', 'germany_package_holidays']\n",
        "    available_series = [s for s in hicp_series if s in long_data['series_name'].unique().to_list()]\n",
        "    \n",
        "    # 1. Seasonal Heatmaps for MoM Changes\n",
        "    for series_name in available_series:\n",
        "        print(f\"\\n1. Seasonal Heatmap - {series_name}\")\n",
        "        \n",
        "        fig_heatmap = viz.create_seasonal_heatmap(\n",
        "            df=long_data,\n",
        "            value_col='mom_pct_change',\n",
        "            series_name=series_name,\n",
        "            title=f\"Seasonal Patterns: {series_name.replace('_', ' ').title()} - MoM Changes (%)\"\n",
        "        )\n",
        "        \n",
        "        # Add annotations for insights\n",
        "        fig_heatmap.update_layout(\n",
        "            annotations=[\n",
        "                dict(\n",
        "                    text=\"Red = Price Increases | Blue = Price Decreases<br>Look for consistent summer (Jun-Aug) patterns\",\n",
        "                    xref=\"paper\", yref=\"paper\",\n",
        "                    x=0.5, y=-0.1,\n",
        "                    showarrow=False,\n",
        "                    font=dict(size=12),\n",
        "                    xanchor=\"center\"\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "        fig_heatmap.show()\n",
        "    \n",
        "    # 2. Seasonal Decomposition\n",
        "    for series_name in available_series:\n",
        "        print(f\"\\n2. Seasonal Decomposition - {series_name}\")\n",
        "        \n",
        "        fig_decomp = viz.create_seasonal_decomposition(\n",
        "            df=long_data,\n",
        "            series_name=series_name,\n",
        "            value_col='value_filled',\n",
        "            title=f\"Seasonal Decomposition Analysis\"\n",
        "        )\n",
        "        fig_decomp.show()\n",
        "    \n",
        "    # 3. Monthly Box Plots for Seasonality\n",
        "    print(f\"\\n3. Monthly Distribution Analysis\")\n",
        "    \n",
        "    # Create monthly box plots for MoM changes\n",
        "    if available_series:\n",
        "        # Focus on the primary series\n",
        "        primary_series = available_series[0]\n",
        "        \n",
        "        fig_monthly = viz.create_box_plot(\n",
        "            df=long_data.filter(pl.col('series_name') == primary_series),\n",
        "            value_col='mom_pct_change',\n",
        "            group_col='month',\n",
        "            title=f\"Monthly MoM Changes Distribution - {primary_series.replace('_', ' ').title()}\"\n",
        "        )\n",
        "        \n",
        "        # Update x-axis labels to month names\n",
        "        month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
        "                      'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "        fig_monthly.update_layout(\n",
        "            xaxis=dict(\n",
        "                tickmode='array',\n",
        "                tickvals=list(range(1, 13)),\n",
        "                ticktext=month_names\n",
        "            )\n",
        "        )\n",
        "        fig_monthly.show()\n",
        "    \n",
        "    # 4. Seasonal Analysis by Quarter\n",
        "    print(f\"\\n4. Quarterly Seasonal Analysis\")\n",
        "    \n",
        "    if available_series:\n",
        "        fig_quarterly = viz.create_box_plot(\n",
        "            df=long_data.filter(pl.col('series_name') == available_series[0]),\n",
        "            value_col='mom_pct_change',\n",
        "            group_col='season',\n",
        "            title=f\"Seasonal MoM Changes by Quarter - {available_series[0].replace('_', ' ').title()}\"\n",
        "        )\n",
        "        fig_quarterly.show()\n",
        "    \n",
        "    # 5. Calculate and Display Seasonal Statistics\n",
        "    print(f\"\\n5. Seasonal Statistics Summary\")\n",
        "    \n",
        "    for series_name in available_series:\n",
        "        series_data = long_data.filter(pl.col('series_name') == series_name)\n",
        "        \n",
        "        if not series_data.is_empty():\n",
        "            # Calculate seasonal statistics\n",
        "            seasonal_stats = (\n",
        "                series_data\n",
        "                .filter(pl.col('mom_pct_change').is_not_null())\n",
        "                .group_by(['season'])\n",
        "                .agg([\n",
        "                    pl.col('mom_pct_change').mean().alias('mean_mom_change'),\n",
        "                    pl.col('mom_pct_change').std().alias('std_mom_change'),\n",
        "                    pl.col('mom_pct_change').median().alias('median_mom_change'),\n",
        "                    pl.col('mom_pct_change').count().alias('observations')\n",
        "                ])\n",
        "                .sort('mean_mom_change', descending=True)\n",
        "            )\n",
        "            \n",
        "            print(f\"\\n{series_name.replace('_', ' ').title()} - Seasonal Statistics:\")\n",
        "            print(seasonal_stats)\n",
        "            \n",
        "            # Monthly statistics\n",
        "            monthly_stats = (\n",
        "                series_data\n",
        "                .filter(pl.col('mom_pct_change').is_not_null())\n",
        "                .group_by('month')\n",
        "                .agg([\n",
        "                    pl.col('mom_pct_change').mean().alias('mean_mom_change'),\n",
        "                    pl.col('mom_pct_change').std().alias('std_mom_change')\n",
        "                ])\n",
        "                .sort('month')\n",
        "            )\n",
        "            \n",
        "            print(f\"\\nMonthly Statistics for {series_name.replace('_', ' ').title()}:\")\n",
        "            print(monthly_stats)\n",
        "            \n",
        "            # Highlight July specifically (our forecast target)\n",
        "            july_stats = monthly_stats.filter(pl.col('month') == 7)\n",
        "            if not july_stats.is_empty():\n",
        "                july_mean = july_stats['mean_mom_change'].item()\n",
        "                july_std = july_stats['std_mom_change'].item()\n",
        "                print(f\"\\n🎯 JULY HISTORICAL PATTERN:\")\n",
        "                print(f\"   Mean MoM Change: {july_mean:.2f}%\")\n",
        "                print(f\"   Standard Deviation: {july_std:.2f}%\")\n",
        "                print(f\"   This provides a baseline for July 2025 forecasting\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ No data available for seasonal analysis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Step 4: Cross-Country and Economic Indicator Analysis\n",
        "\n",
        "Let's analyze the relationships between different countries and economic indicators to understand what drives package holiday price movements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cross-country and economic indicator analysis\n",
        "if wide_data is not None and not wide_data.is_empty():\n",
        "    \n",
        "    print(\"Analyzing cross-country relationships and economic indicators...\")\n",
        "    \n",
        "    # Get list of available variables for correlation analysis\n",
        "    numeric_columns = [col for col in wide_data.columns if col not in ['date', 'year', 'month', 'quarter', 'season', 'is_holiday_season']]\n",
        "    \n",
        "    print(f\"Available variables for analysis: {len(numeric_columns)}\")\n",
        "    \n",
        "    # 1. Correlation Matrix for all series\n",
        "    if len(numeric_columns) >= 2:\n",
        "        print(f\"\\n1. Comprehensive Correlation Matrix\")\n",
        "        \n",
        "        # Focus on key variables (MoM changes)\n",
        "        mom_columns = [col for col in numeric_columns if '_mom_pct' in col or 'mom_pct_change' in col]\n",
        "        value_columns = [col for col in numeric_columns if col in ['eu_package_holidays', 'germany_package_holidays']]\n",
        "        \n",
        "        # Combine key columns for analysis\n",
        "        key_columns = mom_columns + value_columns\n",
        "        key_columns = [col for col in key_columns if col in wide_data.columns]\n",
        "        \n",
        "        if len(key_columns) >= 2:\n",
        "            fig_corr = viz.create_correlation_matrix(\n",
        "                df=wide_data,\n",
        "                variables=key_columns[:10],  # Limit to first 10 for readability\n",
        "                title=\"Correlation Matrix: HICP Series and Economic Indicators\"\n",
        "            )\n",
        "            fig_corr.show()\n",
        "        \n",
        "        # 2. Focus on HICP series correlations\n",
        "        hicp_vars = [col for col in numeric_columns if 'package_holidays' in col and '_mom_pct' in col]\n",
        "        \n",
        "        if len(hicp_vars) >= 2:\n",
        "            print(f\"\\n2. HICP Package Holidays Cross-Country Correlation\")\n",
        "            fig_hicp_corr = viz.create_correlation_matrix(\n",
        "                df=wide_data,\n",
        "                variables=hicp_vars,\n",
        "                title=\"Cross-Country HICP Package Holidays Correlations\"\n",
        "            )\n",
        "            fig_hicp_corr.show()\n",
        "    \n",
        "    # 3. Time series comparison of key indicators\n",
        "    print(f\"\\n3. Economic Indicators vs HICP Analysis\")\n",
        "    \n",
        "    # Look for economic indicators in the data\n",
        "    econ_indicators = []\n",
        "    hicp_mom_vars = [col for col in numeric_columns if 'package_holidays' in col and '_mom_pct' in col]\n",
        "    \n",
        "    # Find economic indicators (non-HICP series)\n",
        "    for col in numeric_columns:\n",
        "        if ('consumer_confidence' in col or 'eur_usd' in col or 'oil_price' in col or \n",
        "            'gdp_growth' in col or 'travel' in col.lower()) and '_mom_pct' in col:\n",
        "            econ_indicators.append(col)\n",
        "    \n",
        "    if hicp_mom_vars and econ_indicators:\n",
        "        # Create combined time series plot\n",
        "        \n",
        "        # Select key variables for plotting\n",
        "        plot_vars = hicp_mom_vars[:2] + econ_indicators[:3]  # Limit for readability\n",
        "        \n",
        "        # Create subplot figure\n",
        "        fig_econ = make_subplots(\n",
        "            rows=len(plot_vars), cols=1,\n",
        "            subplot_titles=[var.replace('_', ' ').title() for var in plot_vars],\n",
        "            vertical_spacing=0.05\n",
        "        )\n",
        "        \n",
        "        colors = COLORS['palette']\n",
        "        \n",
        "        for i, var in enumerate(plot_vars):\n",
        "            if var in wide_data.columns:\n",
        "                # Get non-null data\n",
        "                var_data = wide_data.select(['date', var]).filter(pl.col(var).is_not_null())\n",
        "                \n",
        "                if not var_data.is_empty():\n",
        "                    dates = var_data['date'].to_list()\n",
        "                    values = var_data[var].to_list()\n",
        "                    \n",
        "                    fig_econ.add_trace(\n",
        "                        go.Scatter(\n",
        "                            x=dates, y=values,\n",
        "                            mode='lines',\n",
        "                            name=var.replace('_', ' ').title(),\n",
        "                            line=dict(color=colors[i % len(colors)]),\n",
        "                            showlegend=False\n",
        "                        ),\n",
        "                        row=i+1, col=1\n",
        "                    )\n",
        "                    \n",
        "                    # Add zero line for percentage changes\n",
        "                    if '_mom_pct' in var or '_yoy_pct' in var:\n",
        "                        fig_econ.add_hline(\n",
        "                            y=0, line_dash=\"dash\", line_color=\"gray\", \n",
        "                            opacity=0.3, row=i+1, col=1\n",
        "                        )\n",
        "        \n",
        "        fig_econ.update_layout(\n",
        "            title=\"Economic Indicators vs HICP Package Holidays\",\n",
        "            height=200 * len(plot_vars),\n",
        "            width=1000\n",
        "        )\n",
        "        fig_econ.show()\n",
        "    \n",
        "    # 4. Statistical analysis of relationships\n",
        "    print(f\"\\n4. Statistical Relationship Analysis\")\n",
        "    \n",
        "    if hicp_mom_vars and econ_indicators:\n",
        "        # Calculate cross-correlations\n",
        "        print(\"Cross-correlation analysis between HICP and economic indicators:\")\n",
        "        \n",
        "        for hicp_var in hicp_mom_vars[:2]:  # Focus on main HICP series\n",
        "            print(f\"\\n{hicp_var.replace('_', ' ').title()}:\")\n",
        "            \n",
        "            hicp_data = wide_data.select(['date', hicp_var]).filter(pl.col(hicp_var).is_not_null())\n",
        "            \n",
        "            for econ_var in econ_indicators[:3]:  # Limit for readability\n",
        "                if econ_var in wide_data.columns:\n",
        "                    econ_data = wide_data.select(['date', econ_var]).filter(pl.col(econ_var).is_not_null())\n",
        "                    \n",
        "                    # Merge data for correlation calculation\n",
        "                    merged_data = hicp_data.join(econ_data, on='date', how='inner')\n",
        "                    \n",
        "                    if not merged_data.is_empty() and len(merged_data) > 10:\n",
        "                        # Calculate correlation\n",
        "                        corr_matrix = np.corrcoef(\n",
        "                            merged_data[hicp_var].to_numpy(),\n",
        "                            merged_data[econ_var].to_numpy()\n",
        "                        )\n",
        "                        correlation = corr_matrix[0, 1]\n",
        "                        \n",
        "                        # Interpret correlation strength\n",
        "                        if abs(correlation) >= 0.7:\n",
        "                            strength = \"Strong\"\n",
        "                        elif abs(correlation) >= 0.4:\n",
        "                            strength = \"Moderate\"\n",
        "                        elif abs(correlation) >= 0.2:\n",
        "                            strength = \"Weak\"\n",
        "                        else:\n",
        "                            strength = \"Very Weak\"\n",
        "                        \n",
        "                        print(f\"  vs {econ_var.replace('_', ' ').title()}: {correlation:.3f} ({strength})\")\n",
        "    \n",
        "    # 5. Create summary dashboard for key relationships\n",
        "    print(f\"\\n5. Summary Dashboard\")\n",
        "    \n",
        "    # Focus on the primary HICP series if available\n",
        "    primary_hicp = None\n",
        "    for series in ['eu_package_holidays', 'germany_package_holidays']:\n",
        "        if series in [col.replace('_mom_pct', '') for col in hicp_mom_vars]:\n",
        "            primary_hicp = series\n",
        "            break\n",
        "    \n",
        "    if primary_hicp and long_data is not None:\n",
        "        # Create summary statistics\n",
        "        summary_stats = create_statistical_summary(\n",
        "            long_data.filter(pl.col('series_name') == primary_hicp)\n",
        "        )\n",
        "        \n",
        "        print(f\"\\nSummary Statistics for {primary_hicp.replace('_', ' ').title()}:\")\n",
        "        print(summary_stats)\n",
        "\n",
        "else:\n",
        "    print(\"❌ No wide format data available for correlation analysis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Step 5: Holiday Period Impact Assessment\n",
        "\n",
        "Now let's conduct statistical analysis of summer tourism effects and identify periods of unusual price movements that could inform our July 2025 forecast.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Holiday period impact assessment and statistical analysis\n",
        "if long_data is not None and not long_data.is_empty():\n",
        "    \n",
        "    print(\"Conducting holiday period impact assessment...\")\n",
        "    \n",
        "    # Get available HICP series\n",
        "    hicp_series = ['eu_package_holidays', 'germany_package_holidays']\n",
        "    available_series = [s for s in hicp_series if s in long_data['series_name'].unique().to_list()]\n",
        "    \n",
        "    for series_name in available_series:\n",
        "        print(f\"\\n\" + \"=\"*60)\n",
        "        print(f\"HOLIDAY IMPACT ANALYSIS: {series_name.replace('_', ' ').title()}\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        series_data = long_data.filter(pl.col('series_name') == series_name)\n",
        "        \n",
        "        if series_data.is_empty():\n",
        "            continue\n",
        "        \n",
        "        # 1. Summer vs Non-Summer Statistical Test\n",
        "        print(f\"\\n1. Summer vs Non-Summer Statistical Analysis\")\n",
        "        \n",
        "        summer_data = series_data.filter(pl.col('is_holiday_season') == True)['mom_pct_change'].drop_nulls().to_list()\n",
        "        non_summer_data = series_data.filter(pl.col('is_holiday_season') == False)['mom_pct_change'].drop_nulls().to_list()\n",
        "        \n",
        "        if summer_data and non_summer_data:\n",
        "            # Calculate statistics\n",
        "            summer_mean = np.mean(summer_data)\n",
        "            non_summer_mean = np.mean(non_summer_data)\n",
        "            summer_std = np.std(summer_data)\n",
        "            non_summer_std = np.std(non_summer_data)\n",
        "            \n",
        "            print(f\"Summer months (Jun-Aug):\")\n",
        "            print(f\"  Mean MoM change: {summer_mean:.3f}%\")\n",
        "            print(f\"  Std deviation: {summer_std:.3f}%\")\n",
        "            print(f\"  Observations: {len(summer_data)}\")\n",
        "            \n",
        "            print(f\"Non-summer months:\")\n",
        "            print(f\"  Mean MoM change: {non_summer_mean:.3f}%\")\n",
        "            print(f\"  Std deviation: {non_summer_std:.3f}%\")\n",
        "            print(f\"  Observations: {len(non_summer_data)}\")\n",
        "            \n",
        "            # Perform t-test\n",
        "            if len(summer_data) > 1 and len(non_summer_data) > 1:\n",
        "                try:\n",
        "                    t_stat, p_value = stats.ttest_ind(summer_data, non_summer_data)\n",
        "                    \n",
        "                    print(f\"\\nStatistical Test Results:\")\n",
        "                    print(f\"  T-statistic: {t_stat:.3f}\")\n",
        "                    print(f\"  P-value: {p_value:.3f}\")\n",
        "                    \n",
        "                    if p_value < 0.05:\n",
        "                        print(f\"  Result: SIGNIFICANT difference between summer and non-summer (p < 0.05)\")\n",
        "                        effect_size = summer_mean - non_summer_mean\n",
        "                        print(f\"  Summer effect: {effect_size:+.3f} percentage points\")\n",
        "                    else:\n",
        "                        print(f\"  Result: No significant difference (p >= 0.05)\")\n",
        "                        \n",
        "                except Exception as e:\n",
        "                    print(f\"  Error in statistical test: {e}\")\n",
        "        \n",
        "        # 2. July-specific analysis\n",
        "        print(f\"\\n2. July-Specific Historical Analysis\")\n",
        "        \n",
        "        july_data = series_data.filter(pl.col('month') == 7)\n",
        "        \n",
        "        if not july_data.is_empty():\n",
        "            july_changes = july_data['mom_pct_change'].drop_nulls().to_list()\n",
        "            \n",
        "            if july_changes:\n",
        "                july_mean = np.mean(july_changes)\n",
        "                july_std = np.std(july_changes)\n",
        "                july_median = np.median(july_changes)\n",
        "                july_min = min(july_changes)\n",
        "                july_max = max(july_changes)\n",
        "                \n",
        "                print(f\"July Historical Statistics ({len(july_changes)} observations):\")\n",
        "                print(f\"  Mean: {july_mean:.3f}%\")\n",
        "                print(f\"  Median: {july_median:.3f}%\")\n",
        "                print(f\"  Std Dev: {july_std:.3f}%\")\n",
        "                print(f\"  Range: {july_min:.3f}% to {july_max:.3f}%\")\n",
        "                \n",
        "                # Calculate confidence intervals\n",
        "                if len(july_changes) > 1:\n",
        "                    confidence_interval = stats.t.interval(\n",
        "                        0.68, len(july_changes)-1, \n",
        "                        loc=july_mean, \n",
        "                        scale=stats.sem(july_changes)\n",
        "                    )\n",
        "                    \n",
        "                    print(f\"  68% Confidence Interval: [{confidence_interval[0]:.3f}%, {confidence_interval[1]:.3f}%]\")\n",
        "                    \n",
        "                    # This gives us a baseline for July 2025 forecasting\n",
        "                    print(f\"\\n🎯 JULY 2025 BASELINE FORECAST:\")\n",
        "                    print(f\"   Expected range: {confidence_interval[0]:.2f}% to {confidence_interval[1]:.2f}%\")\n",
        "                    print(f\"   Central estimate: {july_mean:.2f}%\")\n",
        "        \n",
        "        # 3. Outlier detection and analysis\n",
        "        print(f\"\\n3. Outlier Detection and Analysis\")\n",
        "        \n",
        "        mom_changes = series_data['mom_pct_change'].drop_nulls().to_list()\n",
        "        \n",
        "        if len(mom_changes) > 10:\n",
        "            # Calculate IQR for outlier detection\n",
        "            q1 = np.percentile(mom_changes, 25)\n",
        "            q3 = np.percentile(mom_changes, 75)\n",
        "            iqr = q3 - q1\n",
        "            \n",
        "            lower_bound = q1 - 1.5 * iqr\n",
        "            upper_bound = q3 + 1.5 * iqr\n",
        "            \n",
        "            # Find outliers\n",
        "            outlier_data = series_data.filter(\n",
        "                (pl.col('mom_pct_change') < lower_bound) | \n",
        "                (pl.col('mom_pct_change') > upper_bound)\n",
        "            )\n",
        "            \n",
        "            print(f\"Outlier thresholds: [{lower_bound:.2f}%, {upper_bound:.2f}%]\")\n",
        "            print(f\"Number of outliers detected: {len(outlier_data)}\")\n",
        "            \n",
        "            if not outlier_data.is_empty():\n",
        "                print(f\"\\nOutlier events:\")\n",
        "                outlier_summary = (\n",
        "                    outlier_data\n",
        "                    .select(['date', 'mom_pct_change', 'season'])\n",
        "                    .sort('mom_pct_change', descending=True)\n",
        "                )\n",
        "                print(outlier_summary.head(10))\n",
        "        \n",
        "        # 4. Trend analysis over time\n",
        "        print(f\"\\n4. Trend Analysis Over Time\")\n",
        "        \n",
        "        # Group by year to see if seasonal effects are changing\n",
        "        yearly_july = (\n",
        "            series_data\n",
        "            .filter(pl.col('month') == 7)\n",
        "            .filter(pl.col('mom_pct_change').is_not_null())\n",
        "            .group_by('year')\n",
        "            .agg([\n",
        "                pl.col('mom_pct_change').mean().alias('july_mom_change')\n",
        "            ])\n",
        "            .sort('year')\n",
        "        )\n",
        "        \n",
        "        if not yearly_july.is_empty() and len(yearly_july) > 3:\n",
        "            print(f\"July MoM changes by year:\")\n",
        "            print(yearly_july)\n",
        "            \n",
        "            # Simple linear trend analysis\n",
        "            years = yearly_july['year'].to_numpy()\n",
        "            july_values = yearly_july['july_mom_change'].to_numpy()\n",
        "            \n",
        "            if len(years) > 2:\n",
        "                # Calculate linear trend\n",
        "                slope, intercept, r_value, p_value, std_err = stats.linregress(years, july_values)\n",
        "                \n",
        "                print(f\"\\nJuly Trend Analysis:\")\n",
        "                print(f\"  Linear trend slope: {slope:.4f} percentage points per year\")\n",
        "                print(f\"  R-squared: {r_value**2:.3f}\")\n",
        "                print(f\"  P-value: {p_value:.3f}\")\n",
        "                \n",
        "                if p_value < 0.05:\n",
        "                    if slope > 0:\n",
        "                        print(f\"  Result: SIGNIFICANT increasing trend in July changes\")\n",
        "                    else:\n",
        "                        print(f\"  Result: SIGNIFICANT decreasing trend in July changes\")\n",
        "                    \n",
        "                    # Project to 2025\n",
        "                    projected_2025 = intercept + slope * 2025\n",
        "                    print(f\"  Linear projection for July 2025: {projected_2025:.2f}%\")\n",
        "                else:\n",
        "                    print(f\"  Result: No significant trend detected\")\n",
        "    \n",
        "    # 5. Create comprehensive holiday impact visualization\n",
        "    print(f\"\\n\" + \"=\"*60)\n",
        "    print(\"COMPREHENSIVE HOLIDAY IMPACT VISUALIZATION\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    if available_series:\n",
        "        primary_series = available_series[0]\n",
        "        \n",
        "        # Create a comprehensive dashboard\n",
        "        fig_holiday = viz.create_summary_dashboard(\n",
        "            df=long_data.filter(pl.col('series_name') == primary_series),\n",
        "            series_focus=primary_series\n",
        "        )\n",
        "        fig_holiday.show()\n",
        "\n",
        "else:\n",
        "    print(\"❌ No data available for holiday impact assessment\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Step 6: Key Insights and Phase 2 Summary\n",
        "\n",
        "Let's consolidate our findings from the exploratory data analysis and prepare key insights for the next phases of modeling and forecasting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Phase 2 Summary and Key Insights\n",
        "print(\"🎯 PHASE 2: EXPLORATORY DATA ANALYSIS - SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if long_data is not None and not long_data.is_empty():\n",
        "    \n",
        "    # Generate final summary statistics\n",
        "    print(\"\\n📊 DATASET OVERVIEW:\")\n",
        "    print(f\"  • Total observations: {len(long_data):,}\")\n",
        "    print(f\"  • Date range: {long_data['date'].min()} to {long_data['date'].max()}\")\n",
        "    print(f\"  • Series analyzed: {long_data['series_name'].n_unique()}\")\n",
        "    \n",
        "    series_list = long_data['series_name'].unique().to_list()\n",
        "    for series in series_list:\n",
        "        count = long_data.filter(pl.col('series_name') == series).height\n",
        "        print(f\"    - {series}: {count:,} observations\")\n",
        "    \n",
        "    # Key insights from analysis\n",
        "    print(f\"\\n🔍 KEY INSIGHTS DISCOVERED:\")\n",
        "    \n",
        "    # Calculate overall seasonal effect\n",
        "    if 'is_holiday_season' in long_data.columns:\n",
        "        summer_overall = long_data.filter(pl.col('is_holiday_season') == True)['mom_pct_change'].drop_nulls()\n",
        "        non_summer_overall = long_data.filter(pl.col('is_holiday_season') == False)['mom_pct_change'].drop_nulls()\n",
        "        \n",
        "        if not summer_overall.is_empty() and not non_summer_overall.is_empty():\n",
        "            summer_mean = summer_overall.mean()\n",
        "            non_summer_mean = non_summer_overall.mean()\n",
        "            seasonal_effect = summer_mean - non_summer_mean\n",
        "            \n",
        "            print(f\"  • Seasonal Effect: Summer months show {seasonal_effect:+.2f} percentage points difference\")\n",
        "            \n",
        "            if abs(seasonal_effect) > 0.5:\n",
        "                print(f\"    → STRONG seasonal pattern detected - crucial for forecasting\")\n",
        "            else:\n",
        "                print(f\"    → Moderate seasonal pattern - important but not dominant\")\n",
        "    \n",
        "    # July specific insights\n",
        "    july_data_all = long_data.filter(pl.col('month') == 7)['mom_pct_change'].drop_nulls()\n",
        "    if not july_data_all.is_empty():\n",
        "        july_historical_mean = july_data_all.mean()\n",
        "        july_historical_std = july_data_all.std()\n",
        "        \n",
        "        print(f\"  • July Historical Pattern:\")\n",
        "        print(f\"    - Mean MoM change: {july_historical_mean:.2f}%\")\n",
        "        print(f\"    - Standard deviation: {july_historical_std:.2f}%\")\n",
        "        print(f\"    - Sample size: {len(july_data_all)} July observations\")\n",
        "        \n",
        "        # Simple forecast range\n",
        "        forecast_lower = july_historical_mean - july_historical_std\n",
        "        forecast_upper = july_historical_mean + july_historical_std\n",
        "        print(f\"    → July 2025 preliminary range: {forecast_lower:.2f}% to {forecast_upper:.2f}%\")\n",
        "    \n",
        "    # Cross-series correlation insights\n",
        "    hicp_series = ['eu_package_holidays', 'germany_package_holidays']\n",
        "    available_hicp = [s for s in hicp_series if s in long_data['series_name'].unique().to_list()]\n",
        "    \n",
        "    if len(available_hicp) >= 2:\n",
        "        # Calculate cross-correlation\n",
        "        eu_data = long_data.filter(pl.col('series_name') == 'eu_package_holidays')['mom_pct_change'].drop_nulls()\n",
        "        de_data = long_data.filter(pl.col('series_name') == 'germany_package_holidays')['mom_pct_change'].drop_nulls()\n",
        "        \n",
        "        if not eu_data.is_empty() and not de_data.is_empty():\n",
        "            # Simple correlation on overlapping periods\n",
        "            print(f\"  • Cross-Country Dynamics:\")\n",
        "            print(f\"    - EU and Germany series both available\")\n",
        "            print(f\"    → Enables cross-country validation of forecasts\")\n",
        "    \n",
        "    # Data quality assessment\n",
        "    total_missing = long_data['mom_pct_change'].null_count()\n",
        "    total_observations = len(long_data)\n",
        "    missing_pct = (total_missing / total_observations) * 100\n",
        "    \n",
        "    print(f\"  • Data Quality:\")\n",
        "    print(f\"    - Missing MoM data: {missing_pct:.1f}%\")\n",
        "    \n",
        "    if missing_pct < 10:\n",
        "        print(f\"    → Excellent data coverage for reliable forecasting\")\n",
        "    elif missing_pct < 25:\n",
        "        print(f\"    → Good data coverage with minor gaps\")\n",
        "    else:\n",
        "        print(f\"    → Data gaps may require interpolation strategies\")\n",
        "\n",
        "# Prepare outputs for next phases\n",
        "print(f\"\\n📋 OUTPUTS FOR NEXT PHASES:\")\n",
        "print(f\"  • Seasonal patterns identified and quantified\")\n",
        "print(f\"  • July historical baseline established\")\n",
        "print(f\"  • Statistical relationships documented\")\n",
        "print(f\"  • Outlier events catalogued\")\n",
        "print(f\"  • Data quality validated\")\n",
        "\n",
        "print(f\"\\n🚀 READY FOR PHASE 3: SEASONAL ADJUSTMENT\")\n",
        "print(f\"   Next steps:\")\n",
        "print(f\"   1. Implement X-13ARIMA-SEATS equivalent seasonal adjustment\")\n",
        "print(f\"   2. Create custom seasonal factors based on discovered patterns\")\n",
        "print(f\"   3. Develop seasonally adjusted series for modeling\")\n",
        "print(f\"   4. Validate seasonal adjustment quality\")\n",
        "\n",
        "print(f\"\\n📈 PRELIMINARY JULY 2025 INSIGHTS:\")\n",
        "if 'july_historical_mean' in locals():\n",
        "    print(f\"   • Historical July average: {july_historical_mean:.2f}%\")\n",
        "    print(f\"   • Expected range: {forecast_lower:.2f}% to {forecast_upper:.2f}%\")\n",
        "    print(f\"   • Confidence: Based on {len(july_data_all)} historical observations\")\n",
        "else:\n",
        "    print(f\"   • Baseline will be established in subsequent phases\")\n",
        "\n",
        "print(f\"\\n\" + \"=\"*70)\n",
        "print(f\"✅ PHASE 2 COMPLETED SUCCESSFULLY\")\n",
        "print(f\"=\"*70)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
