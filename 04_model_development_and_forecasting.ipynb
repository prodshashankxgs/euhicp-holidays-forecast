{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EU HICP Package Holidays Price Forecast - Phase 4: Model Development & July 2025 Forecasting\n",
        "\n",
        "## Overview\n",
        "This notebook implements **Phase 4** of the EU HICP Package Holidays Price Forecast project, focusing on comprehensive model development and ensemble forecasting for **July 2025**.\n",
        "\n",
        "### Objectives\n",
        "1. **Seasonal Adjustment**: Apply STL decomposition to create seasonally adjusted series\n",
        "2. **Feature Engineering**: Build comprehensive feature store with 80+ features\n",
        "3. **Model Development**: Implement ensemble approach with ARIMA/SARIMA, ML models\n",
        "4. **Validation Framework**: Out-of-sample testing and cross-validation\n",
        "5. **July 2025 Forecast**: Generate final ensemble forecast with confidence intervals\n",
        "6. **Interactive Visualization**: Plotly-based dashboards and analysis\n",
        "\n",
        "### Target\n",
        "**Forecast the seasonally adjusted month-on-month percentage change (MoM% SA) in the HICP index for package holidays in July 2025.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "import json\n",
        "\n",
        "# Time series and ML models\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import xgboost as xgb\n",
        "\n",
        "# Visualization\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "pio.templates.default = \"plotly_white\"\n",
        "\n",
        "# Project modules\n",
        "import sys\n",
        "sys.path.append('.')\n",
        "from seasonal_adjustment import SeasonalAdjuster\n",
        "from feature_engineering import FeatureEngineer\n",
        "\n",
        "# Configure settings\n",
        "pl.Config.set_tbl_rows(20)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✓ All libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load or create sample data\n",
        "try:\n",
        "    df = pl.read_parquet('data/clean_long_format.parquet')\n",
        "    print(f\"✓ Loaded existing data: {len(df)} observations\")\n",
        "except:\n",
        "    print(\"Creating sample data for demonstration...\")\n",
        "    \n",
        "    # Generate sample HICP data with seasonal patterns\n",
        "    dates = pl.date_range(datetime(2010, 1, 1), datetime(2024, 12, 31), interval='1mo')\n",
        "    n_obs = len(dates)\n",
        "    \n",
        "    np.random.seed(42)\n",
        "    trend = np.linspace(100, 120, n_obs)\n",
        "    seasonal = 5 * np.sin(2 * np.pi * np.arange(n_obs) / 12)\n",
        "    noise = np.random.normal(0, 2, n_obs)\n",
        "    \n",
        "    eu_values = trend + seasonal + noise\n",
        "    germany_values = trend * 0.95 + seasonal * 0.8 + np.random.normal(0, 1.5, n_obs)\n",
        "    \n",
        "    eu_df = pl.DataFrame({\n",
        "        'date': dates, 'value': eu_values,\n",
        "        'series_name': ['eu_package_holidays'] * n_obs,\n",
        "        'series_id': ['CP96EAMM'] * n_obs\n",
        "    })\n",
        "    \n",
        "    germany_df = pl.DataFrame({\n",
        "        'date': dates, 'value': germany_values,\n",
        "        'series_name': ['germany_package_holidays'] * n_obs,\n",
        "        'series_id': ['CP96DEMM'] * n_obs\n",
        "    })\n",
        "    \n",
        "    df = pl.concat([eu_df, germany_df])\n",
        "    print(f\"✓ Sample data created: {len(df)} observations\")\n",
        "\n",
        "print(f\"Series: {df['series_name'].unique().to_list()}\")\n",
        "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Seasonal Adjustment & Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply seasonal adjustment and feature engineering\n",
        "print(\"Applying seasonal adjustment...\")\n",
        "\n",
        "# Initialize components\n",
        "adjuster = SeasonalAdjuster(method='stl')\n",
        "engineer = FeatureEngineer()\n",
        "\n",
        "# Process each series\n",
        "adjusted_series = []\n",
        "for series_name in df['series_name'].unique():\n",
        "    try:\n",
        "        adjusted_df = adjuster.adjust_series(df, series_name)\n",
        "        adjusted_series.append(adjusted_df)\n",
        "        print(f\"✓ Processed {series_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed {series_name}: {e}\")\n",
        "\n",
        "# Combine adjusted series\n",
        "if adjusted_series:\n",
        "    seasonally_adjusted_df = pl.concat(adjusted_series)\n",
        "    print(f\"✓ Seasonal adjustment complete: {len(seasonally_adjusted_df)} observations\")\n",
        "else:\n",
        "    seasonally_adjusted_df = df\n",
        "    print(\"❌ Using original data without seasonal adjustment\")\n",
        "\n",
        "# Build feature store\n",
        "print(\"\\nBuilding feature store...\")\n",
        "feature_store = engineer.build_feature_store(seasonally_adjusted_df)\n",
        "\n",
        "# Calculate target variable (MoM% SA)\n",
        "feature_store = feature_store.sort(['series_name', 'date']).with_columns([\n",
        "    (pl.col('value_sa' if 'value_sa' in feature_store.columns else 'value')\n",
        "     .pct_change().over('series_name') * 100).alias('mom_pct_sa')\n",
        "])\n",
        "\n",
        "print(f\"✓ Feature store complete: {feature_store.shape}\")\n",
        "print(f\"  Features: {feature_store.width}\")\n",
        "print(f\"  Target variable: mom_pct_sa\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Interactive Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize seasonal decomposition\n",
        "def plot_seasonal_decomposition(df, series_name):\n",
        "    series_data = df.filter(pl.col('series_name') == series_name).sort('date')\n",
        "    if series_data.is_empty():\n",
        "        return None\n",
        "    \n",
        "    plot_data = series_data.to_pandas()\n",
        "    \n",
        "    fig = make_subplots(\n",
        "        rows=3, cols=1,\n",
        "        subplot_titles=[f'{series_name} - Original vs SA', 'Seasonal', 'Target (MoM% SA)'],\n",
        "        vertical_spacing=0.1\n",
        "    )\n",
        "    \n",
        "    # Original vs seasonally adjusted\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=plot_data['date'], y=plot_data['value'],\n",
        "        name='Original', line=dict(color='blue')\n",
        "    ), row=1, col=1)\n",
        "    \n",
        "    if 'value_sa' in plot_data.columns:\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=plot_data['date'], y=plot_data['value_sa'],\n",
        "            name='Seasonally Adjusted', line=dict(color='red', dash='dash')\n",
        "        ), row=1, col=1)\n",
        "    \n",
        "    # Seasonal component\n",
        "    if 'seasonal' in plot_data.columns:\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=plot_data['date'], y=plot_data['seasonal'],\n",
        "            name='Seasonal', line=dict(color='orange'), showlegend=False\n",
        "        ), row=2, col=1)\n",
        "    \n",
        "    # Target variable\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=plot_data['date'], y=plot_data['mom_pct_sa'],\n",
        "        name='MoM% SA', line=dict(color='green'), showlegend=False\n",
        "    ), row=3, col=1)\n",
        "    \n",
        "    fig.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\", row=3, col=1)\n",
        "    \n",
        "    fig.update_layout(height=800, title=f'Analysis - {series_name}', hovermode='x unified')\n",
        "    return fig\n",
        "\n",
        "# Plot for each series\n",
        "for series_name in feature_store['series_name'].unique():\n",
        "    fig = plot_seasonal_decomposition(feature_store, series_name)\n",
        "    if fig:\n",
        "        fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Model Development & July 2025 Forecasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modeling class for interactive use\n",
        "class JupyterModeler:\n",
        "    def __init__(self, target_col='mom_pct_sa'):\n",
        "        self.target_col = target_col\n",
        "        self.results = {}\n",
        "    \n",
        "    def prepare_data(self, df, series_name):\n",
        "        series_data = df.filter(pl.col('series_name') == series_name).sort('date')\n",
        "        pandas_data = series_data.to_pandas().set_index('date')\n",
        "        \n",
        "        target = pandas_data[self.target_col].dropna()\n",
        "        \n",
        "        exclude_cols = ['series_name', 'series_id', self.target_col]\n",
        "        feature_cols = [col for col in pandas_data.columns if col not in exclude_cols]\n",
        "        features = pandas_data[feature_cols].loc[target.index]\n",
        "        \n",
        "        return target, features\n",
        "    \n",
        "    def fit_sarima(self, target):\n",
        "        try:\n",
        "            model = SARIMAX(target, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
        "            fitted = model.fit(disp=False)\n",
        "            forecast = fitted.forecast(steps=1)[0]\n",
        "            return {'forecast': forecast, 'aic': fitted.aic, 'success': True}\n",
        "        except Exception as e:\n",
        "            return {'success': False, 'error': str(e)}\n",
        "    \n",
        "    def fit_ml_models(self, target, features):\n",
        "        common_idx = target.index.intersection(features.index)\n",
        "        y = target.loc[common_idx]\n",
        "        X = features.loc[common_idx].select_dtypes(include=[np.number])\n",
        "        X = X.loc[:, X.isnull().mean() < 0.5].fillna(X.median())\n",
        "        \n",
        "        if len(y) < 20 or X.shape[1] == 0:\n",
        "            return {}\n",
        "        \n",
        "        models = {\n",
        "            'RandomForest': RandomForestRegressor(n_estimators=50, random_state=42),\n",
        "            'XGBoost': xgb.XGBRegressor(n_estimators=50, random_state=42),\n",
        "            'Ridge': Ridge(alpha=1.0)\n",
        "        }\n",
        "        \n",
        "        results = {}\n",
        "        for name, model in models.items():\n",
        "            try:\n",
        "                if name == 'Ridge':\n",
        "                    scaler = RobustScaler()\n",
        "                    X_scaled = pd.DataFrame(scaler.fit_transform(X), index=X.index, columns=X.columns)\n",
        "                    model.fit(X_scaled, y)\n",
        "                    forecast = model.predict(X_scaled.iloc[-1:].values)[0]\n",
        "                else:\n",
        "                    model.fit(X, y)\n",
        "                    forecast = model.predict(X.iloc[-1:].values)[0]\n",
        "                \n",
        "                mse = mean_squared_error(y, model.predict(X_scaled if name == 'Ridge' else X))\n",
        "                results[name] = {'forecast': forecast, 'mse': mse, 'success': True}\n",
        "            except Exception as e:\n",
        "                results[name] = {'success': False, 'error': str(e)}\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def create_ensemble_forecast(self, individual_forecasts, performance_metrics):\n",
        "        if not individual_forecasts:\n",
        "            return None\n",
        "        \n",
        "        # Weighted average based on inverse MSE\n",
        "        weights = {}\n",
        "        total_weight = 0\n",
        "        \n",
        "        for model in individual_forecasts:\n",
        "            if model in performance_metrics:\n",
        "                weight = 1 / (performance_metrics[model] + 1e-8)\n",
        "            else:\n",
        "                weight = 1\n",
        "            weights[model] = weight\n",
        "            total_weight += weight\n",
        "        \n",
        "        # Normalize weights\n",
        "        weights = {model: w/total_weight for model, w in weights.items()}\n",
        "        \n",
        "        # Calculate ensemble forecast\n",
        "        ensemble_forecast = sum(individual_forecasts[model] * weights[model] for model in individual_forecasts)\n",
        "        \n",
        "        return {\n",
        "            'ensemble_forecast': ensemble_forecast,\n",
        "            'individual_forecasts': individual_forecasts,\n",
        "            'weights': weights\n",
        "        }\n",
        "    \n",
        "    def forecast_july_2025(self, df, series_name):\n",
        "        print(f\"\\nForecasting July 2025 for {series_name}...\")\n",
        "        \n",
        "        target, features = self.prepare_data(df, series_name)\n",
        "        \n",
        "        individual_forecasts = {}\n",
        "        performance_metrics = {}\n",
        "        \n",
        "        # SARIMA\n",
        "        sarima_result = self.fit_sarima(target)\n",
        "        if sarima_result['success']:\n",
        "            individual_forecasts['SARIMA'] = sarima_result['forecast']\n",
        "            performance_metrics['SARIMA'] = sarima_result['aic']\n",
        "            print(f\"  SARIMA forecast: {sarima_result['forecast']:.3f}%\")\n",
        "        \n",
        "        # ML Models\n",
        "        ml_results = self.fit_ml_models(target, features)\n",
        "        for model_name, result in ml_results.items():\n",
        "            if result['success']:\n",
        "                individual_forecasts[model_name] = result['forecast']\n",
        "                performance_metrics[model_name] = result['mse']\n",
        "                print(f\"  {model_name} forecast: {result['forecast']:.3f}%\")\n",
        "        \n",
        "        # Ensemble\n",
        "        ensemble_result = self.create_ensemble_forecast(individual_forecasts, performance_metrics)\n",
        "        \n",
        "        if ensemble_result:\n",
        "            print(f\"  \\n🎯 ENSEMBLE FORECAST: {ensemble_result['ensemble_forecast']:.3f}%\")\n",
        "            print(f\"  Model weights: {ensemble_result['weights']}\")\n",
        "            \n",
        "            # Calculate confidence interval\n",
        "            forecast_values = list(individual_forecasts.values())\n",
        "            forecast_std = np.std(forecast_values)\n",
        "            \n",
        "            ensemble_result['confidence_intervals'] = {\n",
        "                'lower_95': ensemble_result['ensemble_forecast'] - 1.96 * forecast_std,\n",
        "                'upper_95': ensemble_result['ensemble_forecast'] + 1.96 * forecast_std\n",
        "            }\n",
        "            \n",
        "            print(f\"  95% CI: [{ensemble_result['confidence_intervals']['lower_95']:.3f}%, {ensemble_result['confidence_intervals']['upper_95']:.3f}%]\")\n",
        "        \n",
        "        return ensemble_result\n",
        "\n",
        "# Initialize modeler\n",
        "modeler = JupyterModeler()\n",
        "\n",
        "# Generate forecasts for all series\n",
        "forecast_results = {}\n",
        "for series_name in feature_store['series_name'].unique():\n",
        "    result = modeler.forecast_july_2025(feature_store, series_name)\n",
        "    if result:\n",
        "        forecast_results[series_name] = result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Final Results & Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive forecast visualization\n",
        "def create_forecast_dashboard(df, forecast_results):\n",
        "    fig = make_subplots(\n",
        "        rows=2, cols=2,\n",
        "        subplot_titles=[\n",
        "            'Historical MoM% SA Changes',\n",
        "            'July 2025 Forecasts',\n",
        "            'Model Weights',\n",
        "            'Forecast Confidence Intervals'\n",
        "        ],\n",
        "        specs=[[{\"secondary_y\": False}, {\"type\": \"bar\"}],\n",
        "               [{\"type\": \"bar\"}, {\"type\": \"bar\"}]]\n",
        "    )\n",
        "    \n",
        "    # Historical data\n",
        "    for series_name in df['series_name'].unique():\n",
        "        series_data = df.filter(pl.col('series_name') == series_name).sort('date')\n",
        "        plot_data = series_data.to_pandas()\n",
        "        \n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=plot_data['date'], y=plot_data['mom_pct_sa'],\n",
        "            name=series_name, mode='lines+markers'\n",
        "        ), row=1, col=1)\n",
        "    \n",
        "    # July 2025 forecasts\n",
        "    series_names = list(forecast_results.keys())\n",
        "    forecasts = [forecast_results[s]['ensemble_forecast'] for s in series_names]\n",
        "    \n",
        "    fig.add_trace(go.Bar(\n",
        "        x=series_names, y=forecasts,\n",
        "        name='July 2025 Forecast',\n",
        "        marker_color='red'\n",
        "    ), row=1, col=2)\n",
        "    \n",
        "    # Model weights (for first series)\n",
        "    if series_names:\n",
        "        first_series = series_names[0]\n",
        "        weights = forecast_results[first_series]['weights']\n",
        "        \n",
        "        fig.add_trace(go.Bar(\n",
        "            x=list(weights.keys()), y=list(weights.values()),\n",
        "            name='Model Weights',\n",
        "            marker_color='blue'\n",
        "        ), row=2, col=1)\n",
        "    \n",
        "    # Confidence intervals\n",
        "    lower_ci = [forecast_results[s]['confidence_intervals']['lower_95'] for s in series_names]\n",
        "    upper_ci = [forecast_results[s]['confidence_intervals']['upper_95'] for s in series_names]\n",
        "    \n",
        "    fig.add_trace(go.Bar(\n",
        "        x=series_names, y=lower_ci,\n",
        "        name='Lower 95% CI',\n",
        "        marker_color='lightblue'\n",
        "    ), row=2, col=2)\n",
        "    \n",
        "    fig.add_trace(go.Bar(\n",
        "        x=series_names, y=upper_ci,\n",
        "        name='Upper 95% CI',\n",
        "        marker_color='lightcoral'\n",
        "    ), row=2, col=2)\n",
        "    \n",
        "    fig.update_layout(\n",
        "        height=800,\n",
        "        title='EU HICP Package Holidays - July 2025 Forecast Dashboard',\n",
        "        showlegend=True\n",
        "    )\n",
        "    \n",
        "    return fig\n",
        "\n",
        "# Create and show dashboard\n",
        "if forecast_results:\n",
        "    dashboard = create_forecast_dashboard(feature_store, forecast_results)\n",
        "    dashboard.show()\n",
        "    \n",
        "    # Print final summary\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"JULY 2025 FORECAST SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    for series_name, result in forecast_results.items():\n",
        "        print(f\"\\n{series_name.upper()}:\")\n",
        "        print(f\"  Ensemble Forecast: {result['ensemble_forecast']:.3f}%\")\n",
        "        print(f\"  95% Confidence Interval: [{result['confidence_intervals']['lower_95']:.3f}%, {result['confidence_intervals']['upper_95']:.3f}%]\")\n",
        "        print(f\"  Individual Forecasts: {result['individual_forecasts']}\")\n",
        "        print(f\"  Model Weights: {result['weights']}\")\n",
        "    \n",
        "    print(\"\\n🎯 FORECASTING COMPLETE!\")\n",
        "    print(\"The ensemble model has successfully generated July 2025 forecasts for EU HICP Package Holidays.\")\n",
        "else:\n",
        "    print(\"❌ No forecast results generated. Please check the data and model fitting.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
